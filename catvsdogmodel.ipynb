{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "752ae028-9811-4e18-8017-03a9cdcb073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,MaxPool2D,Conv2D,Flatten,BatchNormalization,Dropout\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5446af-a92d-4cb3-99df-c5f02d875dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupted image: D:/ImageClassification\\anaconda_projects\\db\\project_filebrowser.db, Error: cannot identify image file 'D:\\\\ImageClassification\\\\anaconda_projects\\\\db\\\\project_filebrowser.db'\n"
     ]
    }
   ],
   "source": [
    "def corrupt_image(dir):\n",
    "    for root, _, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                img=Image.open(file_path)\n",
    "                img.verify()\n",
    "            except Exception as e:\n",
    "                print(f\"Corrupted image: {file_path}, Error: {e}\")\n",
    "\n",
    "dir = \"D:/ImageClassification\"\n",
    "corrupt_image(dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "214c14ea-3d0f-4340-ace8-c1b0845fde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(\n",
    "    rescale =1.0/255,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip= True,\n",
    "    rotation_range=20,\n",
    "    height_shift_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    zoom_range=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fc858414-3d8e-4407-9a32-fff3dd03d5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=datagen.flow_from_directory(\n",
    "    dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e52e46f2-1ece-43c6-9175-d34d2ed87318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen=datagen.flow_from_directory(\n",
    "    dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1647e1e1-d1c1-4bdf-a9d4-65ea24785c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Conv2D(32,(3,3),input_shape=(150,150,3),activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Conv2D(64,(3,3),activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Conv2D(128,(3,3),activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1,activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "dad797ea-cf29-4579-ad96-e5fe7ba12395",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ce3a4087-0dae-42f6-8f2f-7b250774219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_board=TensorBoard(log_dir='log',histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "df19c3c8-3eaf-405d-97a0-5286ac928734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 5s/step - accuracy: 0.8063 - loss: 0.8597 - val_accuracy: 0.9180 - val_loss: 0.1534\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5s/step - accuracy: 0.9878 - loss: 0.5111 - val_accuracy: 0.0328 - val_loss: 3.4039\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 7.0088e-21 - val_accuracy: 0.6557 - val_loss: 0.8984\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 0.9991 - loss: 0.0021 - val_accuracy: 0.7541 - val_loss: 0.6457\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 1.8575e-21 - val_accuracy: 0.5246 - val_loss: 1.7571\n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 9.6544e-13 - val_accuracy: 0.2787 - val_loss: 2.7452\n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9980 - loss: 0.0664 - val_accuracy: 0.0820 - val_loss: 7.2239\n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9980 - loss: 0.0375 - val_accuracy: 0.2295 - val_loss: 6.6432\n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 4.5932e-06 - val_accuracy: 0.8033 - val_loss: 1.3258\n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 2.7494e-09 - val_accuracy: 0.9016 - val_loss: 0.7724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17b649b99a0>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( train_datagen, epochs=10, callbacks=[ts_board], validation_data=val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "58d1b147-3566-4c00-b5e3-e6617462d089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.8823 - loss: 0.7424\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate(val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535c742-b332-4682-acca-c1d95036b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "def predict_image(model, img_path, target_size=(150, 150)):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    \n",
    "    \n",
    "    if prediction[0][0] > 0.5:\n",
    "        print(f\"Prediction: Class 1 (Positive), Confidence: {prediction[0][0]:.2f}\")\n",
    "    else:\n",
    "        print(f\"Prediction: Class 0 (Negative), Confidence: {1 - prediction[0][0]:.2f}\")\n",
    "\n",
    "\n",
    "image_path = \"D:/ImageClassification/test_image.jpg\"\n",
    "predict_image(model, image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
